---
title: "Assignment 1"
author: "Colin Yip"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(brms)
```

## Exploratory Data Analysis
```{r}
data <- read.table("undisclosedsource.dat", header = TRUE)
```

Distribution plot by diet type. We can ignore run as it is functionally an index.
```{r}
#data$y <- as.factor(data$y)
ggplot(data = data,
       mapping = aes(x = diets, y = y,
                     color = diets)) +
  geom_point() +
  labs(title = "Coagulation Times by Diet",
       x = "Diet", 
       y = "Coagulation Time") +
  theme(legend.position="none")
```
Visually the spread (variance) of the response (coagulation time) across the treatment groups seams to be equal. Groups B and D have slightly higher sample sizes (n = 6) compared to groups A and C (n = 4), but the difference is negligible. On the first look there seem to be one outlier in group B, and D (and perhaps in group C as well). Let us include the order of measurement (collection order), to potentially obtain a more precise picture of the data's distribution.


```{r}
ggplot(data = data,
       mapping = aes(x = run, y = y, color = diets)) +
  geom_point() +
  labs(title = "Collection Order versus Coagulation Time",
       x = "Collection Order", 
       y = "Coagulation Time",
       color = "Diet")

```

There is no real connection between Collection Order and either other variable, so we can ignore the order of measurement as a predictive variable. Visually, there does appear to be a mean difference between B/C and A/D, but the effect of the outlier in D is unknown. The variance between the diets looks fairly similar, once again except for the outlier in D. For this Complete Randomized Design (CRD) with a continuous response and a categorical predictor, we can fit an ANOVA with cornerstone representation and fit the model with a bayesian approach by including prior distributions on the model parameters. Given the small sample size, it is difficult to determine with any power if there is a valid prior distribution, nor is there any additional detail given on if a specific prior is to be assumed. Wen can therefore look at default priors suggested by the brms package, or use frequentist descriptive statistics to manually specify our own priors on the model parameters.

## Model Specification/Training

Check default priors
```{r}
get_prior(formula = y ~ 0 + Intercept + diets, 
          data = data)
```
Brms suggests flat (uniform) priors for the intercept, and for the $\alpha_i$ (difference for each treatment group from the reference mean in the cornerstone representation). Furthermore, it suggests a Studentâ€™s t-distribution with 3 degrees of freedom, a mean of 0, and a scale parameter of 4.4 as a weakly informative prior. This is not very helpful, as the flat priors are both uninformative and provide a support across $\mathbb{R}$ which is illogical in our case. We instead look at the overall and group-specific distributions regarding the response and set our priors manually.

```{r}
data |>
  group_by(diets) |>
  summarise(diet_mu = mean(y),
            diet_sigma = sd(y))
```

We can cornerstone diet A with $N(61, 2)$, and for the differences for the respective diet treatments we can use a normal prior with a mean of 0 and a $\sigma$ that captures the maximal differences from the cornerstone, which in this case is 7 for diet C. A total sample $\sigma$ of roughly 3.8 provides a prior of $Exp(1/3.845)$. 

```{r}
diet_priors <- c(
  set_prior("normal(61, 2)", class = "b", coef = "Intercept"),
  set_prior("normal(0, 10)", class = "b", coef = "dietsB"),
  set_prior("normal(0, 10)", class = "b", coef = "dietsC"),
  set_prior("normal(0, 10)", class = "b", coef = "dietsD"),
  set_prior("exponential(1/3.845)", class = "sigma", lb = 0)
)
```

## Model Fit and Convergence
```{r}
bayesian_diets <- brm(formula = y ~ 0 + Intercept + diets,
                      data = data,
                      prior = diet_priors,
                      seed = 3953629,
                      control = list(adapt_delta = 0.9),
                      chains = 4,
                      cores = 4)

summary(bayesian_diets)
```

Next, we want to investigate the convergence of our MCMC sampling algorithm. The Effective Sample Size (ESS) of over a thousand samples and the potential scale reduction factor of 1 suggest convergence. The Credible Interval (CI) for the estimate for the $\alpha$ on group D includes 0, which suggests that there is no difference in means between group D and the reference group at an alpha level of 0.05. The other two CI of the estimates do not include 0, which suggests that there a differences in the group means between both C and B and the reference group A.


```{r}
# Look at convergence chains here to ensure that a stable solution has been found
mcmc_trace(bayesian_diets)
```
We have stable convergence across all 4 chains through all variables, as we see that each variable above demonstrates the "caterpillar" like behaviour we look for. That is, the values converge in a stable fashion towards a single mode of the presumed underlying distribution. 


```{r}
mcmc_acf(bayesian_diets)
```
We see that the autocorrelation of each chain reduces quite significantly across all variables. This indicates that the chains have indeed checked through the posterior in a relatively complete fashion. High autocorrelation would indicate that a chain has gotten stuck in a single point, indicating that the final values may not be the most optimal globally.

```{r}
regression_R2 <- bayes_R2(bayesian_diets, summary = FALSE)
regression_R2_df <- data.frame(R2 = regression_R2)

regression_R2_df %>%
  ggplot(aes(x = R2)) +
  stat_halfeye() + 
  labs(title = "R^2 of Bayesian Estimate for Diet Effect on Coagulation Time",
       y = "R^2")
```

An estimated $R^2$ of 0.635 indicates moderate but significant positive correlation. In the context of the treatment, this indicates that different treatments explain a significant portion of the variance in patient coagulation time. 63.5% of the total variance can be explained by the sample variance of the predicted values by the posterior.

## Posterior Distributions

## Assumptions Checking


## QQ-Plot

One assumption for ANOVA is that the errors follow a normal distribution. We can test this assumptions using a QQ-plot which plots the errors of our model against the quantiles of a normal distribution. The errors do not considerably deviate from the 45-degree line, which indicates that the errors indeed follow a normal distribution.

```{r}
# Get fitted values from the brms model
fitted_values1 <- fitted(bayesian_diets)
head(fitted_values1)

# Include fitted values and residuals 
bayesian_diets2 <- data %>%
  mutate(fitted = fitted_values1[, 1]) %>%  
  mutate(residuals = y - fitted)

head(bayesian_diets2)

# Plot the residuals
bayesian_diets2 %>%
  ggplot(aes(sample = residuals)) +
  geom_qq_line() +
  geom_qq(colour = "red")

```

```{r}
bayesian_diets2 %>%
  ggplot() +
  geom_point(aes(x = fitted, y = residuals, colour = as_factor(diets))) +
  guides(colour = guide_legend(title = "diet")) +
  scale_colour_viridis(discrete = TRUE) +
  theme(legend.position = "bottom")
```

Another assumption for ANOVA is homogeneity of variance of the errors. The errors (residuals) are expected to be normally distributed with mean 0 and a common variance $\sigma^2$ Therefore, we compare the predicted (fitted) values from our bayesian ANOVA to the residuals (difference between observed values and predictions). We only have the treatment group (diet) as the single predictor of the response, therefore we also only have 4 fitted values (one prediction per group). The residuals seem to be randomly scattered around 0. This indicates that the errors follow our assumptions and that the model captures the relationship between the predictor and the response sufficiently.


## Conclusions