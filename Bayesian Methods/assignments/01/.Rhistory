## 4: much less than usual.
## Or reversed if the item is counter indicative:
## 1: not at all
## 2: not more than usual
## 3: a bit more than usual
## 4: much more than usual
"S327", ## Can you concentrate on the things you're busy with lately?
"S328", ## Have you lost sleep over worries lately?
"S329", ## Do you have the feeling that your activities are useful and meaningful?
"S330", ## Do you feel able to make decisions lately?
"S331", ## Do you have the feeling that you are constantly under pressure lately?
"S332", ## Do you have the feeling that you can't manage your problems lately?
"S333", ## Do you have pleasure in your daily activities lately?
"S335", ## Did you feel unhappy and dejected lately?
"S336", ## Did you lose self-confidence lately?
"S337", ## Did you consider yourself a worthless person lately?
"S338" ## On the whole, did you feel reasonably happy lately?
)
Gender <- c("M4") ## Identifies as 0 (woman) or 1 (man)
Study.delay87 <- c("M232") ## Years (0 through ...)
Age87 <- c("M37") ## Years (17 through 27)
all = c(Impulsivity87, General.psychological.health87, Gender, Study.delay87, Age87)
data_all = dat[, all]
# delete rows with missing values
data_all = na.omit(data_all)
# convert items to numeric data type
df_imp = as.data.frame(sapply(data_all[ , Impulsivity87], as.numeric))
df_GPH = as.data.frame(sapply(data_all[ , General.psychological.health87], as.numeric))
df_gender = as.data.frame(sapply(data_all[ , Gender], as.numeric))
df_studydelay = as.data.frame(sapply(data_all[ , Study.delay87], as.numeric))
df_age = as.data.frame(sapply(data_all[ , Age87], as.numeric))
# handle missing data (delete all rows with missing data)
df_imp[ , "S279"] <- 8L - df_imp[ , "S279"] # revert items
df_imp[ , "S269"] <- 8L - df_imp[ , "S269"]
# get total test score for impulsivity and GPH
imp_total = as.data.frame(rowSums(df_imp))
GPH_total = as.data.frame(rowSums(df_GPH))
# descriptive statistics for item scores
imp_item_stats = psych::describe(df_imp)
GPH_item_stats = psych::describe(df_GPH)
# and for total test score
psych::describe(imp_total)
psych::describe(GPH_total)
# Plot descriptive stats from item scores on impulsivity and general psychological health
df_stats_imp = as.data.frame(lapply(imp_item_stats, function(x) round(x, 2)))
df_stats_GPH = as.data.frame(lapply(GPH_item_stats, function(x) round(x, 2)))
df_stats_imp[c("vars", "trimmed", "mad")] = NULL
df_stats_GPH[c("vars", "trimmed", "mad")] = NULL
# add item names
item = rownames(imp_item_stats)
df_stats_imp = cbind(item, df_stats_imp)
item = rownames(GPH_item_stats)
df_stats_GPH = cbind(item, df_stats_GPH)
# Plot the data frame as a table
#ggtexttable(df_stats_imp, rows = NULL, theme = ttheme("light"))
kable(df_stats_imp)
#ggtexttable(df_stats_GPH, rows = NULL, theme = ttheme("light"))
kable(df_stats_GPH)
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
library(lavaan)
library("foreign")
library(psych)
library(ggplot2)
library(corrplot) #plotting correlation matrices
library(semPlot)  #for automatically making diagrams
library("knitr")
library(ggpubr)
dat <- read.spss("TOTAAL.SAV", to.data.frame = TRUE)
Satisfaction87 <- c(
## Likert scale response: 1 (helemaal niet van toepassing / not at all applicable)
## through 7 (volledig van toepassing / completely applicable)
"S341", # In most respects my life is ideal
"S342", # My life conditions are exellent
"S343" # Overall I am satisfied with my life
)
Satisfaction91 <- c(
## Likert scale response: --- (helemaal niet van toepassing / not at all applicable)
## through +++ (volledig van toepassing / completely applicable)
"SS281", # In most respects my life is ideal
"SS282", # My life conditions are exellent
"SS283" # Overall I am satisfied with my life
)
dat[,Satisfaction87]
dat1 <- sapply(dat[, c(Satisfaction87, Satisfaction91)], as.numeric)
dat1 = as.data.frame(dat1)
dat1= na.omit(dat1)
#descriptives (means, sds)
describe(dat1)
library(lavaan)
library("foreign")
library(psych)
library(ggplot2)
library(corrplot) #plotting correlation matrices
library(semPlot)  #for automatically making diagrams
library("knitr")
library(ggpubr)
dat <- read.spss("TOTAAL.SAV", to.data.frame = TRUE)
Satisfaction87 <- c(
## Likert scale response: 1 (helemaal niet van toepassing / not at all applicable)
## through 7 (volledig van toepassing / completely applicable)
"S341", # In most respects my life is ideal
"S342", # My life conditions are exellent
"S343" # Overall I am satisfied with my life
)
Satisfaction91 <- c(
## Likert scale response: --- (helemaal niet van toepassing / not at all applicable)
## through +++ (volledig van toepassing / completely applicable)
"SS281", # In most respects my life is ideal
"SS282", # My life conditions are exellent
"SS283" # Overall I am satisfied with my life
)
dat[,Satisfaction87]
dat1 <- sapply(dat[, c(Satisfaction87, Satisfaction91)], as.numeric)
dat1 = as.data.frame(dat1)
dat1= na.omit(dat1)
#descriptives (means, sds)
describe(dat1)
covmat = cov(dat1)
covmat
kable(as.data.frame(covmat))
#visusal correlation matrix
corrplot(cor(dat1), order = "original", tl.col='black', tl.cex=.75)
# Fit a two-factor model on the 1987 and 1991 life satistfaction questionnaires
two_factor_model <- '
# Factor 1 (Life satisfaction 1987) loads on S341, S342, S343
F1 =~ l11*S341 + l21*S342 + l31*S343
# Factor 2 (Life satisfaction 1991) loads on SS281, SS282, SS283
F2 =~ l42*SS281 + l52*SS282 + l62*SS283
# Covariance between the two latent factors
F1 ~~ F2
# Correlated residuals
S341 ~~ SS281
S342 ~~ SS282
S343 ~~ SS283
# Variances of latent factors (set to 1 for identification)
F1 ~~ 1*F1
F2 ~~ 1*F2
'
# n = 1245 after removement of missing values
n_obs = dim(dat1)[1]
# Fit the model using lavaan and auto.fix = TRUE (sets the first factor loading to 1 for each latent factor)
two_factor_fit_out <- lavaan::cfa(two_factor_model, sample.cov = covmat, sample.nobs = n_obs, auto.fix.first = F)
# Print the summary of the fit
summary(two_factor_fit_out, fit.measures = TRUE, standardized = TRUE)
# Plot the two-factor model
# Create a scaled version of your factor model to enhance covariance visibility
# Scale factor (choose a value that makes sense based on your covariances)
scale_factor <- 5  # Adjust this value as needed
# Fit the model as before (assuming factor_model1 is already fitted)
# Now use semPaths to plot
semPaths(two_factor_fit_out,
what = "est",
edge.label.cex = 0.95,           # Increase edge label size
sizeLat = 4,
sizeMan = 4,
fade = FALSE,  # Makes the edges more visible
edge.width=0.5,
edge.color = "black",         # Change edge color for better contrast
edge.label.color = "green",      # Edge label color
layout = "tree")                 # Choose a layout that fits your data
# Get indicator means and store them in a vector
mean_vec = sapply(dat1, mean)
mean_vec
## STEP 1: define longitudinal model without equality constraints
## Configural invariance. Fit the same factor model to all time points (with residual covariances).
## fix factor variances to 1 and factor means to 0
long_inv_model <- '
# COVARIANCES
# regression equations
F1 =~ l11*S341 + l21*S342 + l31*S343
# Factor 2 (Life satisfaction 1991) loads on SS281, SS282, SS283
F2 =~ l42*SS281 + l52*SS282 + l62*SS283
# Covariance between the two latent factors
F1 ~~ F2
# residual covariances
S341 ~~ SS281
S342 ~~ SS282
S343 ~~ SS283
# residual variances
S341 ~~ S341
S342 ~~ S342
S343 ~~ S343
SS281 ~~ SS281
SS282 ~~ SS282
SS283 ~~ SS283
# common factor (co)variances (set to 1 for identification)
F1 ~~ F2
F1 ~~ 1*F1
F2 ~~ 1*F2
# MEANS
# intercepts observed indicators
S341 ~ 1
S342 ~ 1
S343 ~ 1
SS281 ~ 1
SS282 ~ 1
SS283 ~ 1
# means common factors (fix the means to 0 (configural invariance))
F1 ~ 0*1
F2 ~ 0*1
'
## run the model
long_inv_model_out = lavaan(long_inv_model, sample.cov = covmat,
sample.mean = mean_vec, sample.nobs = n_obs,
likelihood = "normal", fixed.x = FALSE)
## output
summary(long_inv_model_out)
# Plot the configural invariance model
# Create a scaled version of your factor model to enhance covariance visibility
# Scale factor (choose a value that makes sense based on your covariances)
scale_factor <- 5  # Adjust this value as needed
# Fit the model as before (assuming factor_model1 is already fitted)
# Now use semPaths to plot
semPaths(long_inv_model_out,
what = "est",
edge.label.cex = 0.95,           # Increase edge label size
sizeLat = 4,
sizeMan = 4,
fade = FALSE,  # Makes the edges more visible
edge.width=0.5,
edge.color = "black",         # Change edge color for better contrast
edge.label.color = "green",      # Edge label color
layout = "tree")                 # Choose a layout that fits your data
# STEP 2 test for weak factorial invariance
## additional constrain factor loadings to be equal across occasions
## STEP 1: define longitudinal model without equality constraints
## Configural invariance. Fit the same factor model to all time points (with residual covariances).
## fix factor variances to 1 and factor means to 0
long_inv_weak <- '
# COVARIANCES
# regression equations
F1 =~ l11*S341 + l21*S342 + l31*S343
# Factor 2 (Life satisfaction 1991) loads on SS281, SS282, SS283
F2 =~ l11*SS281 + l21*SS282 + l31*SS283
# Covariance between the two latent factors
F1 ~~ F2
# residual covariances
S341 ~~ SS281
S342 ~~ SS282
S343 ~~ SS283
# residual variances
S341 ~~ S341
S342 ~~ S342
S343 ~~ S343
SS281 ~~ SS281
SS282 ~~ SS282
SS283 ~~ SS283
# common factor (co)variances
F1 ~~ F2
F1 ~~ 1*F1
F2 ~~ F2 # free second factor variance
# MEANS
# intercepts observed indicators
S341 ~ 1
S342 ~ 1
S343 ~ 1
SS281 ~ 1
SS282 ~ 1
SS283 ~ 1
# means common factors
F1 ~ 0*1
F2 ~ 0*1
'
## run the model
long_weak_inv_out = lavaan(long_inv_weak, sample.cov = covmat,
sample.mean = mean_vec, sample.nobs = n_obs,
likelihood = "normal", fixed.x = FALSE)
## output
summary(long_weak_inv_out)
anova(long_inv_model_out, long_weak_inv_out) # tests if the more complex model (configural invariance) has a significantly worse fit than the more sparse (weak invariance) model
# STEP 2 test for weak factorial invariance
## additional constrain factor loadings to be equal across occasions
## STEP 1: define longitudinal model without equality constraints
## Configural invariance. Fit the same factor model to all time points (with residual covariances).
## fix factor variances to 1 and factor means to 0
long_inv_weak <- '
# COVARIANCES
# regression equations
F1 =~ l11*S341 + l21*S342 + l31*S343
# Factor 2 (Life satisfaction 1991) loads on SS281, SS282, SS283
F2 =~ l11*SS281 + l21*SS282 + l31*SS283
# Covariance between the two latent factors
F1 ~~ F2
# residual covariances
S341 ~~ SS281
S342 ~~ SS282
S343 ~~ SS283
# residual variances
S341 ~~ S341
S342 ~~ S342
S343 ~~ S343
SS281 ~~ SS281
SS282 ~~ SS282
SS283 ~~ SS283
# common factor (co)variances
F1 ~~ F2
F1 ~~ 1*F1
F2 ~~ F2 # free second factor variance
# MEANS
# intercepts observed indicators
S341 ~ 1
S342 ~ 1
S343 ~ 1
SS281 ~ 1
SS282 ~ 1
SS283 ~ 1
# means common factors
F1 ~ 0*1
F2 ~ 0*1
'
## run the model
long_weak_inv_out = lavaan(long_inv_weak, sample.cov = covmat,
sample.mean = mean_vec, sample.nobs = n_obs,
likelihood = "normal", fixed.x = FALSE)
## output
summary(long_weak_inv_out)
anova(long_inv_model_out, long_weak_inv_out) # tests if the more complex model (configural invariance) has a significantly worse fit than the more sparse (weak invariance) model
#RMSEA
RMSEA_configural = fitMeasures(long_inv_model_out, "RMSEA")
RMSEA_weak = fitMeasures(long_weak_inv_out, "RMSEA")
RMSEA_configural
RMSEA_weak
#CFI
CFI_configural = fitMeasures(long_inv_model_out, "cfi")
CFI_weak = fitMeasures(long_weak_inv_out, "cfi")
diff_CFI = CFI_configural - CFI_weak
diff_CFI
# Plot model with weak invariance
# Create a scaled version of your factor model to enhance covariance visibility
# Scale factor (choose a value that makes sense based on your covariances)
scale_factor <- 5  # Adjust this value as needed
# Fit the model as before (assuming factor_model1 is already fitted)
# Now use semPaths to plot
semPaths(long_weak_inv_out,
what = "est",
edge.label.cex = 0.95,           # Increase edge label size
sizeLat = 4,
sizeMan = 4,
fade = FALSE,  # Makes the edges more visible
edge.width=0.5,
edge.color = "black",         # Change edge color for better contrast
edge.label.color = "green",      # Edge label color
layout = "tree")                 # Choose a layout that fits your data
# STEP 3: Test for strong strong factorial invariance
## 1) Constrain intercepts to be equal across occasions (all previous restrictions still hold)
## 2) Free all factor means except the one of the first group
long_strong_inv <- '
# COVARIANCES
# regression equations (equal factor loadings)
F1 =~ l11*S341 + l21*S342 + l31*S343
# Factor 2 (Life satisfaction 1991) loads on SS281, SS282, SS283
F2 =~ l11*SS281 + l21*SS282 + l31*SS283
# Covariance between the two latent factors
F1 ~~ F2
# residual covariances
S341 ~~ SS281
S342 ~~ SS282
S343 ~~ SS283
# residual variances
S341 ~~ S341
S342 ~~ S342
S343 ~~ S343
SS281 ~~ SS281
SS282 ~~ SS282
SS283 ~~ SS283
# common factor (co)variances, free one vactor variance
F1 ~~ F2
F1 ~~ 1*F1
F2 ~~ F2
# MEANS
# Intercepts are supposed to be equal across both groups
S341 ~ I1*1
S342 ~ I2*1
S343 ~ I3*1
SS281 ~ I1*1
SS282 ~ I2*1
SS283 ~ I3*1
# Free all factor means except the one from the first group
F1 ~ 0*1
F2 ~ 1
'
## run the model
long_strong_inv_out = lavaan(long_strong_inv, sample.cov = covmat,
sample.mean = mean_vec, sample.nobs = n_obs,
likelihood = "normal", fixed.x = FALSE)
## output
summary(long_strong_inv_out)
anova(long_weak_inv_out, long_strong_inv_out)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(brms)
library(latex2exp)
library(emmeans)
library(bayesplot)
library(tidybayes)
library(forcats)
#data$y <- as.factor(data$y)
ggplot(data = data,
mapping = aes(x = diets, y = y,
color = diets)) +
geom_point() +
labs(title = "Coagulation Times by Diet",
x = "Diet",
y = "Coagulation Time") +
theme(legend.position="none")
data <- read.table("undisclosedsource.dat", header = TRUE)
#data$y <- as.factor(data$y)
ggplot(data = data,
mapping = aes(x = diets, y = y,
color = diets)) +
geom_point() +
labs(title = "Coagulation Times by Diet",
x = "Diet",
y = "Coagulation Time") +
theme(legend.position="none")
ggplot(data = data,
mapping = aes(x = run, y = y, color = diets)) +
geom_point() +
labs(title = "Collection Order versus Coagulation Time",
x = "Collection Order",
y = "Coagulation Time",
color = "Diet")
get_prior(formula = y ~ 0 + Intercept + diets,
data = data)
data |>
group_by(diets) |>
summarise(diet_mu = mean(y),
diet_sigma = sd(y))
diet_priors <- c(
set_prior("normal(61, 2)", class = "b", coef = "Intercept"),
set_prior("normal(0, 10)", class = "b", coef = "dietsB"),
set_prior("normal(0, 10)", class = "b", coef = "dietsC"),
set_prior("normal(0, 10)", class = "b", coef = "dietsD"),
set_prior("exponential(1/3.845)", class = "sigma", lb = 0)
)
bayesian_diets <- brm(formula = y ~ 0 + Intercept + diets,
data = data,
prior = diet_priors,
seed = 3953629,
control = list(adapt_delta = 0.9),
chains = 4,
cores = 4)
summary(bayesian_diets)
mcmc_trace(bayesian_diets)
mcmc_acf(bayesian_diets)
regression_R2 <- bayes_R2(bayesian_diets, summary = FALSE)
regression_R2_df <- data.frame(R2 = regression_R2)
regression_R2_df %>%
ggplot(aes(x = R2)) +
stat_halfeye() +
labs(title = "R^2 of Bayesian Estimate for Diet Effect on Coagulation Time",
y = "Density")
# Get fitted values from the brms model
fitted_values1 <- fitted(bayesian_diets)
# Include fitted values and residuals
bayesian_diets2 <- data %>%
mutate(fitted = fitted_values1[, 1]) %>%
mutate(residuals = y - fitted)
# Plot the residuals
bayesian_diets2 %>%
ggplot(aes(sample = residuals)) +
geom_qq_line() +
geom_qq(colour = "red") +
labs(title=TeX("Q-Q Plot for Normality of Residuals, $\\hat{e}$"),
x="Theoretical Quantiles",
y="Sample Quantiles")
bayesian_diets2 %>%
ggplot() +
geom_point(aes(x = fitted, y = residuals, colour = as.factor(diets))) +
guides(colour = guide_legend(title = "Diet")) +
theme(legend.position = "bottom") +
geom_hline(yintercept=0, size=0.2, linetype='dashed', colour = "red") +
labs(title=TeX("Residuals vs. Fitted Values"),
x="Fitted Values",
y=TeX("Residuals, $\\hat{e}_{jk}$"))
bayesian_emmeans <- emmeans(bayesian_diets, pairwise ~ diets)
diet_marginals <- bayesian_diets |>
spread_draws(c(b_Intercept, b_dietsB, b_dietsC, b_dietsD)) |>
mutate(A = b_Intercept,
B = b_Intercept + b_dietsB,
C = b_Intercept + b_dietsC,
D = b_Intercept + b_dietsD) |>
gather_draws(A, B, C, D)
ggplot(data = diet_marginals,
aes(x = .value, y = .variable)) +
stat_halfeye() +
labs(x = "Diet Treatment Mean",
y = "Diet",
title = "Marginal Means of Diet Effects on Coagulation Time")
pairs(bayesian_emmeans)
ggplot(data = diet_marginals |>
compare_levels(variable = .value,
by = .variable,
comparison = "pairwise"),
aes(x = .value, y = .variable)) +
stat_halfeye() +
labs(x = "Differences",
y = "Contrasts",
title = "Difference of Diet Effects on Coagulation Time") +
geom_vline(xintercept = 0, colour = "red", linetype = "dashed")
p_vals = c(0.0012, 0.0033, 0.0035, 0.0054, 0.0091)
# Step 2: Apply the Holm-Bonferroni correction
p_values_holm <- p.adjust(p_vals, method = "holm")
# Step 3: Print the adjusted p-values
print(p_values_holm)
p_vals = c(0.0012, 0.0033, 0.0035, 0.0054, 0.0091)
# Step 2: Apply the Holm-Bonferroni correction
p_values_holm <- p.adjust(p_vals, method = "holm")
# Step 3: Print the adjusted p-values
print(p_values_holm)
